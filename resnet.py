# -*- coding: utf-8 -*-
# """SRGAN.ipynb
#
# Automatically generated by Colaboratory.
#
# Original file is located at
#     https://colab.research.google.com/drive/1iGilK-vufPeFgG6oVEw-ztIybWgDa9Gg
# """
#
# from google.colab import drive
# drive.mount('/content/drive')
#
# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl
# !pip3 install torchvision
# !pip3 install Pillow==4.1.1

import torch
import torchvision
import torchvision.transforms as transforms
import torchvision.models as models
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import torch.optim as optim
import random
from collections import Counter
import pickle
from PIL import Image
import torch.utils.data as data
import os
from datetime import datetime
from torch.utils.data import Dataset
import math
from torchvision.models.vgg import vgg16
from math import log10
import time
import pandas as pd
import torch.optim as optim
import torch.utils.data
import torchvision.utils as utils
from torch.autograd import Variable
from torch.utils.data import DataLoader

params = {'train_data_dir': '/u/training/tra398/scratch/SR/Data/train_images_64x64',
          'train_target_dir': '/u/training/tra398/scratch/SR/Data/train_images_128x128',
          'test_data_dir': '/u/training/tra398/scratch/SR/Data/test_images_64x64',
          'output_dir':'/u/training/tra398/scratch/SR/Resnet/Output'}

def load_image(filename, target = False):
    img = Image.open(filename)
    img = img.convert('RGB')
    return img

class XrayDataset(Dataset):
    def __init__(self, filenames, data_path, target_path=None, data_transform=None, target_transform=None):
        self.data_path = data_path
        self.target_path = target_path
        self.filenames = filenames
        self.data_transforms = data_transform
        self.target_transforms = target_transform

    def __getitem__(self, index):
        image = self.filenames[index]
        data = load_image(os.path.join(self.data_path, image))
        if self.target_path != None:
            target = load_image(os.path.join(self.target_path, image), True)
        if self.data_transforms != None:
            data = self.data_transforms(data)
        if self.target_transforms != None:
            target = self.target_transforms(target)
        if self.target_path == None:
            return data, image
        else:
            return data, target

    def __len__(self):
        return len(self.filenames)

trans = transforms.Compose([transforms.ToTensor()])
filenames = os.listdir(params['train_data_dir'])
xray_dataset = XrayDataset(filenames[0:15550], params['train_data_dir'], params['train_target_dir'], trans, trans)
val_xray_dataset = XrayDataset(filenames[15551:],params['train_data_dir'], params['train_target_dir'], trans, trans)

data_loader = torch.utils.data.DataLoader(dataset=xray_dataset,
                                          batch_size=32,
                                          shuffle=True,
                                          num_workers=32)
val_data_loader = torch.utils.data.DataLoader(dataset=val_xray_dataset,
                                               batch_size=32,
                                               shuffle=False,
                                               num_workers=32)

import torch
import torch.nn as nn
import math

class _Residual_Block(nn.Module):
    def __init__(self):
        super(_Residual_Block, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)
        self.in1 = nn.InstanceNorm2d(64, affine=True)
        self.relu = nn.LeakyReLU(0.2, inplace=True)
        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)
        self.in2 = nn.InstanceNorm2d(64, affine=True)

    def forward(self, x):
        identity_data = x
        output = self.relu(self.in1(self.conv1(x)))
        output = self.in2(self.conv2(output))
        output = torch.add(output,identity_data)
        return output

def save_images(data, filenames, output_dir):
    num_images = data.size()[0]
    trans = transforms.ToPILImage()
    for i in range(num_images):
        image = data[i]
        image = trans(image)
        image
        image.convert("RGB")
        image.save(os.path.join(output_dir, filenames[i]), "PNG")


class _NetG(nn.Module):
    def __init__(self):
        super(_NetG, self).__init__()

        self.conv_input = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4, bias=False)
        self.relu = nn.LeakyReLU(0.2, inplace=True)

        self.residual = self.make_layer(_Residual_Block, 16)

        self.conv_mid = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn_mid = nn.InstanceNorm2d(64, affine=True)

        self.upscale4x = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False),
            nn.PixelShuffle(2),
            nn.LeakyReLU(0.2, inplace=True)
        )

        self.conv_output = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=9, stride=1, padding=4, bias=False)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()

    def make_layer(self, block, num_of_layer):
        layers = []
        for _ in range(num_of_layer):
            layers.append(block())
        return nn.Sequential(*layers)

    def forward(self, x):
        out = self.relu(self.conv_input(x))
        residual = out
        out = self.residual(out)
        out = self.bn_mid(self.conv_mid(out))
        out = torch.add(out,residual)
        out = self.upscale4x(out)
        out = self.conv_output(out)
        return out

model = _NetG()
criterion = nn.MSELoss(size_average=False)

model.cuda()
criterion.cuda()

optimizer = optim.Adam(model.parameters(), lr=0.0001)

state_dict = torch.load(os.path.join(params['output_dir'], "model_epoch_13.pth"))
model.load_state_dict(state_dict['model'])
optimizer.load_state_dict(state_dict['optimizer'])

def adjust_learning_rate(optimizer, epoch):
    lr = 0.0001 * (0.1 ** (epoch // 10))
    return lr

def train(training_data_loader, optimizer, model, criterion, epoch):
    time1 = time.time()
    lr = adjust_learning_rate(optimizer, epoch-1)

    for param_group in optimizer.param_groups:
        param_group["lr"] = lr

    print("Epoch={}, lr={}".format(epoch, optimizer.param_groups[0]["lr"]))
    model.train()
    total_loss = []
    for iteration, batch in enumerate(training_data_loader, 1):
        for group in optimizer.param_groups:
            for p in group['params']:
                state = optimizer.state[p]
                if('step' in state and state['step']>=1024):
                    state['step'] = 1000

        input, target = Variable(batch[0]), Variable(batch[1], requires_grad=False)

        input = input.cuda()
        target = target.cuda()
        output = model(input)
        loss = criterion(output, target)
        total_loss.append(loss.data[0])
        optimizer.zero_grad()

        loss.backward()

        optimizer.step()

        if iteration%100 == 0:
            print("===> Epoch[{}]({}/{}): Loss: {:.5}".format(epoch, iteration, len(training_data_loader), np.sum(total_loss)))
        #break
    time2 = time.time()
    print("Total loss after epoch {} is {}. Time taken is {}".format(epoch, np.sum(total_loss), (time2-time1)))

def save_checkpoint(model, epoch, optimizer):
    model_out_path = params['output_dir'] + "/model_epoch_{}.pth".format(epoch)
    state = {"epoch": epoch ,"model": model.state_dict(), 'optimizer':optimizer.state_dict()}
    torch.save(state, model_out_path)
    print("Checkpoint saved to {}".format(model_out_path))


for epoch in range(14, 500):
      train(data_loader, optimizer, model, criterion, epoch)
      save_checkpoint(model, epoch, optimizer)

      if (epoch%20 == 0):
          test_filenames = os.listdir(params['test_data_dir'])
          test_xray_dataset = XrayDataset(test_filenames,params['test_data_dir'], None, trans, None)
          test_data_loader = torch.utils.data.DataLoader(dataset=test_xray_dataset,
                                                         batch_size=32,
                                                         shuffle=False,
                                                         num_workers=32)

          model.eval()
          total = 0
          with torch.no_grad():
              for i, (input_image, filenames) in enumerate(test_data_loader):
                input_image = Variable(input_image).cuda()
                hr_images = model(input_image)
                total += hr_images.size()[0]
                hr_images = hr_images.cpu()
                if not os.path.exists(os.path.join(params['output_dir'], ('output_images' + str(epoch)))):
                    os.makedirs(os.path.join(params['output_dir'], ("output_images"+str(epoch))))
                save_images(hr_images, filenames, os.path.join(params['output_dir'], ("output_images"+str(epoch))))
